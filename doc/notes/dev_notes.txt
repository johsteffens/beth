/// Author & Copyright (C) 2017 Johannes Steffens <johannes.b.steffens@gmail.com>. All rights reserved.

Running notes about ongoing beth development.

My thoughts and notes (slightly less unreadable than the pen&paper doodly/scratchy stuff)
to help remember/record the 'when/what/why' of development.

## Memory Management (March-May 2017) ##

   # Initial thoughts (March-April 2017) #
   Why explicit memory management (vs just using the system's manager)?
     --> allocator may grant client more memory than requested and tell him about it
     --> deallocator can receive (optionally) extra information (e.g. granted amount) to quicker locate the descriptor
     --> better monitoring of memory use
     --> processing better optimized for handling small amounts

   How to organize?
     --> Desriptor location
          - near memory block (+better size dynamics; -more descuctive in case of overwrites;)
          - in dedicated area (+safe; -slower or need of advanced logic (s.below)
          --> opt for the latter

   # Serious Development (April-May 2017) #
   alloc/free/realloc speed of small memory amounts matter most.
   The client's use of memory is normally least as large as one write and one read cycle O(size).
   --> Memory manager's footprint becomes significant for small amounts.

   Hypothesis: Particularly in OOP and/or polymorphic environments allocation frequency
               of relates inverse exponentially to the size requested.
               P given size ~ e^-(size^q); q > 0;

   ==> Handle 'small' amounts; e.g. up to page size by own manager; redirect larger amounts to the system.

   Current design:
     Token manager:  manages blocks of equal size up to a fixed amount
     Block manager:  Dynamically maintains multiple token managers (of same block size) according to running memory needs
     Memory manager: Dynamically maintains multiple block managers of different block size;
                     Exponential block size distribution.

    Additional feature: Token manager's state is header of designated memory area; Memory block is aligned by large value;
                        O(1) time for finding header from any alloc address by projecting to aligned address;
                        Token is calculated from distance to header.

    Allocation request (O(1)):
       * Determine Block Manager via requested amount.
       * Locate free token manager. (Allocate new one if all are full)
       * Take token.
          * Check full state and possibly tell block manager
       * Grant block size of token manager.

    Deallocation request O(1) or O(log(n))
       * Decide if internally or externally handled O(log(n) if size is unknown; O(1) if size is known.
       * Locate token manager (via projection). O(1)
       * Return token. O(1)
          * Check free or empty state and possibly tell block manager
       * When above O(1) methods are not possible, lookups is done via btree (O(log(n)).

       * Current solution faster than system's malloc, free, the deallocating client tells mm about granted size.
         (Telling about granted space is usually not a problem because in far most cases objects are aware
          of that size without the need to store additional data).

## Dynamic types (April-July 2017) ##
   * Dynamic type management is achieved by associating each object-type (including plain value types) with a unique
     integer. That integer may be calculated from a text-based type-name via hashing or from the type signature
     (anonymous types). Other associative ways are also thinkable.

## Aware types (April 2017) ##
   * Aware types achieve type introspection via attribute-data pairing in their logical data model.
     (s. also:  https://en.wikipedia.org/wiki/Attribute-value_pair; https://en.wikipedia.org/wiki/Type_introspection)

   * The type-integer (s. above) is stored as first data element of the instance followed by the actual data (value)
     of the instance. This allows a quick runtime type determination by interpreting a pointer to the instance as pointer
     to the type-integer.

   * Suitable integer formats (32bit int, 64bit int) usually do not exceed the size of a pointer. Hence the storage
     overhead of aware objects is equal or below the storage overhead of (instances of) traditional oop-classes with
     virtual functions (e.g. C++).

   * Not all types need be aware. Traditional (primitive) value-types should be allowed to remain unaware to allow optimal
     storage efficiency. They can be converted to aware types when appropriate. (A related procedure in C# is called
     'boxing'). This puts a load on object models supporting dynamic typing, because support externally typed
     (short: 'typed objects') object as well as aware objects need to be carried along.

## Object-Interface-Association (May 2017) ##
   * Interfaces shall be dynamically bound to objects via types (rather than statically or via (virtual) pointers,
     as done in C++).
   * Associations are resolved via hash map; results can be cached as needed.
   * Advantage:    Reduced dependencies between interface and object. Greater flexibility.
   * Disadvantage: Extra overhead in resolving associations and cache management.

## Reflection (April 2017) ##
   * Each object has a reflection (a database of types), describing its data elements, associated functions, names
     and attributes.
   * A reflection can be used to reconstruct the data model of an object and determine associated functions at runtime.
   * The reflection includes names of objects, which are hashed like types (s. above).

## Perspective (May 2017) ##
   * A perspective is a higher-order-object describing other objects and providing generic functionality for those
     object and/or managing polymorphism.
   * A perspective makes extensive use of reflection and object-interface-association (s. above).

## Distinction of beth from other oop-languages: (June 2017) ##

    * reflective (type structure is known at runtime)

    * all types are final (!)
      --> no virtual types
      --> no inheritance
      --> no type casting (except from an anonymous type)
      --> but: members of composite types can be of static or variable type

    * Anonymous types
      A type can contain anonymous types.
      -> the actual type is stored in a variable
      -> the variable can be owned by the enclosing type (typed objects)
      -> the variable can be owned by the type itself (aware types)

    * C-programs: type safety checked at runtime (--> not all type errors can be detected, though --> still careful programming required)
    * beth-programs: type safety checked at compile time as best as possible

    * Perspectives are stateless
    * Interfaces are perspectives
    * Operators (on composite-types) would be perspectives
    * The perspective is a new programming paradigm located between OOP and procedural programming
    * Perspectives can implement concepts once in a generic way (which would require a design pattern in other languages)
    * Concepts are easily interchangeable (e.g. different ways of marshaling)

## Cuckoo Hashing ## (June 2017)
30 June 2017 (experimental results):
    2 stage vs 3 or higher stage hashing:
    - 2 stage achieves near 50% memory efficiency
    - 3 stage achieves near 90% memory efficiency
    - 3 stage can be several orders of magnitude slower than 2 stage when approaching the occupation limit.
        The extra storage space does not seem justify the storage CPU overhead.

  Hash functions (2 stage)
    LCG mapping:
      Simple lcg mapping for the key value is fastest but provides poor statistics to achieve
      desired storage efficiency (EFF around 6% at 2^16).

    XSG mapping:
      (32 bit) xsg mapping is significantly better than LCG.
      Statistical deficiency begins showing when the database size exceeds about 2^16 entries.
      Space 2^16 : Eff. 45%
      Space 2^26 : Eff. 20%
      Space 2^29 : Eff. 10%

    Fold-hashing:
      Iterative 8 or 16 bit folding seems even better. (1-time 32 bit is not working well)
      FNV can be used but it seems that any form hash = ( hash ^ data ) * <prime> with large enough prime and
      large enough initial seems to work equally well. Preferably choose initial=const such that
      hash = ( hash ^ <const> ) * <prime> performs a full cycle.

      Space 2^29 : Eff. 43%
      Space 2^30 : Eff. 45%

   --> cuckoo hashing with minimal two-stage fold-hashing seems best
   --> hmap shall be based on that concept


## Amoebic Functions (July 2017) ##
17 July 2017:
    Amoeba (-Function)
      We introduce the term "amoeba" for a function-abstraction representing class of functions,
      which signature is defined by an object passed by reference. We call this object nucleus.
      The terms are borrowed from the biological term amoeba as being a organism without predefined shape.

      The nucleus is owned/managed by the caller.

      From the viewpoint of the language the signature of an amoeba is fixed
      void (*)( void* ptr_to_nucleus ).

      From the viewpoint of the program the function's signature and purpose is defined by the nucleus.
      It contains fields used as arguments and fields for the return values. The amoeba is a simple way to
      use functions as first class objects in languages that do not provide this feature natively.

    Amoebic representation of a feature (Amoebic feature)
      The amoebic feature describes a feature implementation where its fulfillment is spread
      across two functions, one on the object side and one on the perspective-side. One of these is
      an amoebic function, which controls the fulfillment. The function pointer points to the non-amoebic
      function.

      The nucleus of the amoebic feature has a well defined structure composed in this order: a function pointer,
      a perspective pointer, the list of arguments of the non-amoebic feature, return object/value
      (can be omitted when function returns void).
      This might be seen as the pespective-paradigm eqivalent to the overload-default relationship in the OOP-
      paradigm.

## Closures (July-Aug 2017) ##

1 Aug 2017:
   Thoughts and experiments about c-style closures (so far) condensed into the following design:
   We define a closure as (aware) object providing one function with following features
     * A specified number of arguments
     * A specified type per argument
     * Specified attributes per argument (currently f_eval and f_const)
       -> f_const argument is not changed by function
       -> f_eval  argument's state influences result
       --> for pure return type(s) f_const == false && f_eval == false;
     * A specified const indicator, indicating if the function can changes the closure's
       inner state.

   The state of specifiers is dynamic (retrievable via features) and determined by closure's inner state,
   although it seems prudent to disallow a non-const closure have its state of specifiers modified by its
   closure-function.

   The closure's return value (if any) is part or the argument list (no explicit C-style return value)
   More than one return values are possible.

   All argument-objects are externally owned and created. (The closure does not create its return objects either.)
   The caller creates these objects using the closure's specifier for return types.

   A specific functor converts a closure by turning some arguments into inner parameters of the resulting closure.
   Nevertheless, the ownership of corresponding objects stays outside the closure such that the validity of the
   closure's inner state may become (partially) the responsibility of the caller.
   (This is a compromise across conflicting use cases in the absence of garbage collection)

2 Aug 2017:
   Principal goals currently pursued with the C-style closure framework
   * Introducing function-objects (first class objects)
   * Self-reflection for functions
   * Lexical scope (runtime) function definition and execution
   * --> framework becomes layer for higher language
   * Functional programming
   * Translation into static functions (compilation)
   * Translation into an efficiently executable state at runtime (JIT compilation)


